{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecb15d9-ea6d-407f-85e5-3fc4da29ce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cloud notebooks, uncomment to install huggingface/diffusers\n",
    "#! pip install diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b90551-4ee9-4ab8-b800-03c3eca25972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from diffusers import StableDiffusionPipeline, AutoPipelineForImage2Image\n",
    "\n",
    "from diffusers.pipelines.pipeline_utils import numpy_to_pil\n",
    "from transformers import CLIPTokenizer, CLIPTextModel\n",
    "from diffusers import AutoencoderKL, UNet2DConditionModel, \\\n",
    "        PNDMScheduler, LMSDiscreteScheduler\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea29f0ca-c012-4a5c-b453-852298e9d38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def grid_show(images, rows=3):\n",
    "\n",
    "    number_images = len(images)\n",
    "    height, width = images[0].size\n",
    "    \n",
    "    columns = int(np.ceil(number_images / rows))\n",
    "    grid = np.zeros((height*rows,width*columns,3)) #Image.new(\"RGB\", size=(width*columns, height*rows))\n",
    "    for ii, image in enumerate(images):\n",
    "        grid[ii//columns*height:ii//columns*height+height, \\\n",
    "                ii%columns*width:ii%columns*width+width] = image\n",
    "    fig, ax = plt.subplots(1,1, figsize=(3*columns, 3*rows))\n",
    "    ax.imshow(grid / grid.max())\n",
    "    return grid, fig, ax\n",
    "\n",
    "def callback_stash_latents(ii, tt, latents):\n",
    "    # adapted from https://github.com/fastai/diffusion-nbs/stable_diffusion.ipynb\n",
    "    latents = 1.0 / 0.18215 * latents\n",
    "    image = pipe.vae.decode(latents).sample[0]\n",
    "    image = (image / 2. + 0.5).cpu().permute(1,2,0).numpy()\n",
    "    image = np.clip(image, 0, 1.0)\n",
    "    images.extend(pipe.numpy_to_pil(image))\n",
    "\n",
    "my_seed = 27\n",
    "assert my_seed < 2**32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63e567b-a49a-4821-abcd-abb45814953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this cell to run on CPU, or to choose another model. \n",
    "if (1):\n",
    "    #Run CompVis/stable-diffusion-v1-4 on GPU\n",
    "    pipe_name = \"CompVis/stable-diffusion-v1-4\"\n",
    "    my_dtype = torch.float16\n",
    "    my_device = torch.device(\"cuda\")\n",
    "    my_variant = \"fp16\"\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(pipe_name,\\\n",
    "                    safety_checker=None, variant=my_variant, torch_dtype=my_dtype).to(my_device)\n",
    "elif (0):\n",
    "    #Run CompVis/stable-diffusion-v1-4 on CPU. \n",
    "    pipe_name = \"CompVis/stable-diffusion-v1-4\"\n",
    "    my_dtype = torch.float32 #torch.float16\n",
    "    my_device = torch.device(\"cpu\") #torch.device(\"cuda\")\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(pipe_name, torch_dtype=my_dtype).to(my_device)\n",
    "    #pipe = StableDiffusionPipeline.from_pretrained(pipe_name, torch_dtype=my_dtype, variant=\"fp16\").to(my_device)\n",
    "else:\n",
    "    #Run stabilityai/stable-diffusion-xl-base-1.0 on GPU (keep in mind your VRAM usage)\n",
    "    pipe_name = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "    my_dtype = torch.float32\n",
    "    my_device = torch.device(\"cpu\")\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(pipe_name, torch_dtype=my_dtype).to(my_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4895900d-71f7-4680-bcba-a98d6f8415d4",
   "metadata": {},
   "source": [
    "# Pareidolia: Finding Patterns in Noise\n",
    "\n",
    "[https://en.wikipedia.org/wiki/Pareidolia](https://en.wikipedia.org/wiki/Pareidolia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75e906a-281a-4a7e-8352-6a463e554c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_prompt = \"Rorschach test ink blot looks like emoji\"\n",
    "seed_all(my_seed)\n",
    "my_output = pipe(my_prompt, num_inference_steps=50, num_images_per_prompt=9, guidance_scale=9.0)\n",
    "temp = grid_show(my_output.images, rows=3)\n",
    "plt.show()\n",
    "\n",
    "for ii, img in enumerate(my_output.images):\n",
    "    img.save(f\"latte_{my_seed}_{ii}.jpg\")\n",
    "    \n",
    "    \n",
    "my_prompt = \"ðŸ˜¬ inadvertent ðŸ˜¬ latte art face, accidental latte art, cozy, detail, intricate, cafe, coffee\"\n",
    "seed_all(my_seed)\n",
    "my_output = pipe(my_prompt, num_inference_steps=50, num_images_per_prompt=9, guidance_scale=9.0)\n",
    "temp = grid_show(my_output.images, rows=3)\n",
    "plt.show()\n",
    "\n",
    "for ii, img in enumerate(my_output.images):\n",
    "    img.save(f\"latte_{my_seed}_{ii}.jpg\")\n",
    "\n",
    "my_prompt = \"piece of toasted bread bears the likeness of a realistic human face on golden-brown burnt toast surface, shroud\"\n",
    "seed_all(my_seed)\n",
    "my_output = pipe(my_prompt, num_inference_steps=50, num_images_per_prompt=9, guidance_scale=9.0)\n",
    "temp = grid_show(my_output.images, rows=3)\n",
    "plt.show()\n",
    "\n",
    "for ii, img in enumerate(my_output.images):\n",
    "    img.save(f\"toast_{my_seed}_{ii}.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e996da-14da-4c8f-a991-63a1c1fe627e",
   "metadata": {},
   "source": [
    "# Latent Diffusion: The Pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a844d3-d54f-4c5c-a274-a6f7ee1fb650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare latent diffusion components\n",
    "prompt = [\"Robotic lunar rover, NASA, JPL/Caltech\"]\n",
    "seed_all(my_seed)\n",
    "\n",
    "# image settings\n",
    "height, width = 512, 512\n",
    "\n",
    "#diffusion settings\n",
    "number_inference_steps = 64\n",
    "guidance_scale = 9.0\n",
    "batch_size = 1\n",
    "\n",
    "# diffusion pieces\n",
    "vae = AutoencoderKL.from_pretrained(\"CompVis/stable-diffusion-v1-4\", \\\n",
    "        subfolder=\"vae\")\n",
    "tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "unet = UNet2DConditionModel.from_pretrained(\"CompVis/stable-diffusion-v1-4\",\\\n",
    "        subfolder=\"unet\")\n",
    "scheduler = LMSDiscreteScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", num_train_timesteps=1000)\n",
    "#PNDMScheduler()\n",
    "scheduler.set_timesteps(number_inference_steps)\n",
    "\n",
    "vae = vae.to(my_device)\n",
    "text_encoder = text_encoder.to(my_device)\n",
    "unet = unet.to(my_device)\n",
    "\n",
    "prompt = prompt * batch_size\n",
    "# initialize text embeddings\n",
    "tokens = tokenizer(prompt, padding=\"max_length\",\\\n",
    "        max_length=tokenizer.model_max_length, truncation=True,\\\n",
    "        return_tensors=\"pt\")\n",
    "\n",
    "empty_tokens = tokenizer([\"\"] * batch_size, padding=\"max_length\",\\\n",
    "        max_length=tokenizer.model_max_length, truncation=True,\\\n",
    "        return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    text_embeddings = text_encoder(tokens.input_ids.to(my_device))[0]\n",
    "    max_length = tokens.input_ids.shape[-1]\n",
    "    \n",
    "    notext_embeddings = text_encoder(empty_tokens.input_ids.to(my_device))[0]\n",
    "\n",
    "text_embeddings = torch.cat([notext_embeddings, text_embeddings])\n",
    "\n",
    "# initialize latent space\n",
    "latents = torch.randn(batch_size, unet.config.in_channels, height//8, width//8)\n",
    "latents = latents * scheduler.init_noise_sigma\n",
    "latents = latents.to(my_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbd1d24-8af2-4766-bd53-ad0d55962498",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "display_every = number_inference_steps // 8\n",
    "\n",
    "# diffusion loop\n",
    "for step_idx, timestep in enumerate(scheduler.timesteps):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_in = torch.cat([latents] * 2)\n",
    "        model_in = scheduler.scale_model_input(model_in, timestep).to(my_device)\n",
    "\n",
    "        predicted_noise = unet(model_in, timestep, \\\n",
    "                encoder_hidden_states=text_embeddings).sample\n",
    "\n",
    "        # pnu - empty prompt unconditioned noise prediction\n",
    "        # pnc - text prompt conditioned noise prediction\n",
    "        pnu, pnc = predicted_noise.chunk(2)\n",
    "        # weight noise predictions\n",
    "        predicted_noise = pnu + guidance_scale * (pnc - pnu)\n",
    "\n",
    "        # update the latents\n",
    "        latents = scheduler.step(predicted_noise, \\\n",
    "                timestep, latents).prev_sample\n",
    "\n",
    "        if step_idx % display_every == 0\\\n",
    "                or step_idx + 1 == len(scheduler.timesteps):\n",
    "            image = vae.decode(latents / 0.18215).sample[0]\n",
    "            image = ((image / 2.) + 0.5).cpu().permute(1,2,0).numpy()\n",
    "            image = np.clip(image, 0, 1.0)\n",
    "            \n",
    "            images.extend(numpy_to_pil(image))\n",
    "\n",
    "            print(f\"step {step_idx}/{number_inference_steps}: {timestep:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e1caed-3fab-4526-8cec-5af178591973",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = grid_show(images)\n",
    "plt.savefig(\"pieces.jpg\")\n",
    "images[-1].save(\"lunar_rover_pieces.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c68b735-3b58-4667-82d3-4ee41ccb3260",
   "metadata": {},
   "source": [
    "# The Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63dcd69-8780-4a44-964a-6b37e7bd810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_prompt = \"Artist's impression of first astronaut on Mars giving a thumbs-up ðŸ‘ after discovering fungoid alien Martian life\"\\\n",
    "        \", hyper-realistic, realism, retro-futuristic, intricate, detailed, golden hour\"\n",
    "\n",
    "seed_all(my_seed)\n",
    "\n",
    "images = []\n",
    "my_output = pipe(my_prompt, num_inference_steps=50, callback=callback_stash_latents, \\\n",
    "        callback_steps=6, num_images_per_prompt=1, guidance=8.0)\n",
    "\n",
    "images.append(my_output.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b83515a-0812-4c02-9c67-8542060916b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = grid_show(images, rows=3)\n",
    "plt.savefig(\"astro_denoising.jpg\")\n",
    "plt.show()\n",
    "\n",
    "my_output.images[0].save(\"denoised_astro.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d896b766-769a-4402-a174-0897d20a488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(my_seed)\n",
    "my_output_astro = pipe(my_prompt, num_inference_steps=50, num_images_per_prompt=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a50846-65ce-46c0-9fc1-346a2f5902c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = grid_show(my_output_astro.images)\n",
    "plt.show()\n",
    "for ii, img in enumerate(my_output_astro.images):\n",
    "    img.save(f\"human_astro_{my_seed}_{ii}.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d246f5-a50a-465d-b463-defc6ac2982a",
   "metadata": {},
   "source": [
    "# Negative Prompts\n",
    "\n",
    "Tell the diffusion pipeline what to avoid for better control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa22815-7010-448d-b51b-fa2b50219a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_prompt = \"Artist's impression of first astronaut on Mars giving a thumbs-up ðŸ‘ after discovering fungoid alien Martian life\"\\\n",
    "        \", hyper-realistic, realism, retro-futuristic, intricate, detailed, golden hour\"\n",
    "\n",
    "my_negative_prompt = \"human, astronaut, person, man, woman, Earthling\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9503bf-0d50-4dcd-872a-8cf10f8dde45",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(my_seed)\n",
    "my_output_alien = pipe(my_prompt, num_inference_steps=50, num_images_per_prompt=9, \\\n",
    "        negative_prompt=my_negative_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13db32e-1759-441b-92b3-6a206c4945bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = grid_show(my_output_alien.images)\n",
    "plt.show()\n",
    "\n",
    "for ii, img in enumerate(my_output_alien.images):\n",
    "    img.save(f\"nonhuman_astro_{my_seed}_{ii}.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8812df-901c-4b43-8650-52f0ed5f80c2",
   "metadata": {},
   "source": [
    "# Guidance\n",
    "\n",
    "Control how latents are updated by changing how strongly the text and null embedding are weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400477d6-979f-4b78-ad96-a034ff619815",
   "metadata": {},
   "outputs": [],
   "source": [
    "guidance_images = []\n",
    "    \n",
    "for guidance in [0.25, 0.5, 1., 2.0, 4.0, 6.0, 8.0, 10.0, 14.0]:\n",
    "    seed_all(my_seed)\n",
    "    my_output = pipe(my_prompt, num_inference_steps=50, num_images_per_prompt=1, guidance_scale=guidance)\n",
    "    guidance_images.append(my_output.images[0])\n",
    "     \n",
    "    for ii, img in enumerate(my_output.images):\n",
    "        img.save(f\"mice_{my_seed}_g{int(guidance*2)}_tea3_{ii}.jpg\")\n",
    "\n",
    "temp = grid_show(guidance_images, rows=3) #my_output.images, rows=3)\n",
    "plt.savefig(\"cozy_mice_guidance.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f962dc82-934b-438a-aaf6-da5ba02b33f9",
   "metadata": {},
   "source": [
    "# Starting from an Initial Image\n",
    "\n",
    "Use an initial image as a sketch for inpainting, outpainting, image-to-image variation, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1565cd38-2116-4a83-b197-d17f2fac1915",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_img2img = AutoPipelineForImage2Image.from_pretrained(\\\n",
    "    \"runwayml/stable-diffusion-v1-5\", torch_dtype=my_dtype, use_safetensors=True).to(my_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261fa8c5-7ffc-440f-b5ba-4996212a22fa",
   "metadata": {},
   "source": [
    "# Image variation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f269b374-b61e-4890-afaf-fb420e052c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (os.path.exists(\"600px-TRAPPIST-1e_artist_impression_2018.png\")):\n",
    "    os.system(\"wget 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/38/TRAPPIST-1e_artist_impression_2018.png/600px-TRAPPIST-1e_artist_impression_2018.png'\")\n",
    "\n",
    "init_image = Image.open(\"600px-TRAPPIST-1e_artist_impression_2018.png\").resize((128,128)).resize((512,512))\n",
    "\n",
    "init_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a459d97-66a6-4ba6-858a-f47f941de7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(my_seed)\n",
    "\n",
    "trappist_prompt = \"Artist's impression of TRAPPIST-1e, a rocky water-world exoplanet ocean-bearing world,\"\\\n",
    "        \" orbiting within the habitable (or Goldilocks) zone\"\\\n",
    "        \" of the ultracool dwarf star TRAPPIST-1\"\\\n",
    "        \"NASA, artist concept, , detailed, intricate, art, reconstruction\"\n",
    "\n",
    "my_output_trappist1e = pipe_img2img(prompt=trappist_prompt, num_images_per_prompt=9, \\\n",
    "        image=init_image, guidance_scale=5.0)\n",
    "\n",
    "grid_show(my_output_trappist1e.images)\n",
    "plt.show()\n",
    "\n",
    "for ii, img in enumerate(my_output_trappist1e.images):\n",
    "    img.save(f\"trappist1e_waterocean_{my_seed}_{ii}.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753915ba-075f-468a-9900-a20bcf6ea4ec",
   "metadata": {},
   "source": [
    "# Use an initial image as a starting sketch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd228dad-d9c7-4eae-85f6-b62b42543a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# https://www.jpl.nasa.gov/news/chasing-oumuamua\n",
    "if not (os.path.exists(\"imagesasteroid20180627Oumuamua.2e16d0ba.fill-400x400-c50.gif\")):\n",
    "    os.system(\"wget 'https://d2pn8kiwq2w21t.cloudfront.net/images/imagesasteroid20180627Oumuamua.2e16d0ba.fill-400x400-c50.gif'\")\n",
    "\n",
    "init_image = Image.open(\"imagesasteroid20180627Oumuamua.2e16d0ba.fill-400x400-c50.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a10ab0-c45e-4569-9d20-0558af24e1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_image.seek(80)\n",
    "init_image = init_image.resize((512,512))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36d02ef-e994-42d3-b156-df228216a979",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(my_seed)\n",
    "\n",
    "oumuamua_prompt = \"Interstellar object\"\\\n",
    "        \" Oumuamua is an elongated alien spacecraft\"\\\n",
    "        \" artist concept, reconstruction, realistic render, NASA/JPL-Caltech \"\n",
    "my_negative_prompt = \"normal asteroid\"\n",
    "\n",
    "oumuamua = pipe_img2img(prompt=oumuamua_prompt, num_images_per_prompt=9, \\\n",
    "        image=init_image, guidance_scale=10.0, negative_prompt=my_negative_prompt)\n",
    "\n",
    "grid_show(oumuamua.images)\n",
    "plt.show()\n",
    "\n",
    "for ii, img in enumerate(oumuamua.images):\n",
    "    img.save(f\"oumuamua_{my_seed}_{ii}.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50f918c-ea6f-48d1-bbf9-ef992c32534a",
   "metadata": {},
   "source": [
    "# Change the style of an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcfa8a7-16b8-4936-924f-3598ad7ce858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://photojournal.jpl.nasa.gov/catalog/PIA04413\n",
    "\n",
    "if not (os.path.exists(\"300px-NASA_Mars_Rover.jpg\")):\n",
    "    os.system(\"wget 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d8/NASA_Mars_Rover.jpg/300px-NASA_Mars_Rover.jpg'\")\n",
    "\n",
    "init_image = Image.open(\"300px-NASA_Mars_Rover.jpg\").crop((0,0,256,256)).resize((512,512))\n",
    "\n",
    "seed_all(my_seed)\n",
    "\n",
    "rover_prompt = \"Cute cartoon watercolor of NASA's Mars Opportunity rover, doing a good job on Mars\"\\\n",
    "        \", cozy, space, NASA, watercolour, art\"\n",
    "\n",
    "rover_wc = pipe_img2img(prompt=rover_prompt, num_images_per_prompt=9, \\\n",
    "            image=init_image, guidance_scale=10.0)\n",
    "\n",
    "grid_show(rover_wc.images)\n",
    "plt.show()\n",
    "\n",
    "for ii, img in enumerate(rover_wc.images):\n",
    "    img.save(f\"rover_wc_{my_seed}_{ii}.jpg\")\n",
    "    my_cmap = plt.get_cmap(\"plasma\")\n",
    "    \n",
    "    fig, ax = plt.subplots(1,2, figsize=(8,4))\n",
    "    ax[1].imshow(init_image)\n",
    "    ax[1].set_title(\"Initial image\")\n",
    "    ax[0].imshow(img)\n",
    "    ax[0].set_title(\"After diffusion (watercolor)\")\n",
    "    \n",
    "    fig.text(.44, .35, \"â†’\", color=my_cmap(192), fontsize=128)\n",
    "    \n",
    "    for idx in range(2):\n",
    "        ax[idx].set_yticklabels(\"\")\n",
    "        ax[idx].set_xticklabels(\"\")\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631ba985-72d2-40e1-8fe1-4afdc82ace4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
